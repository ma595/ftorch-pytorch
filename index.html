<!DOCTYPE html>
<html lang="en"><head>
<script src="pytorch-FTorch_files/libs/clipboard/clipboard.min.js"></script>
<script src="pytorch-FTorch_files/libs/quarto-html/tabby.min.js"></script>
<script src="pytorch-FTorch_files/libs/quarto-html/popper.min.js"></script>
<script src="pytorch-FTorch_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="pytorch-FTorch_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="pytorch-FTorch_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="pytorch-FTorch_files/libs/quarto-html/quarto-syntax-highlighting-dark-54c8f25464f32f8783bd446cee98020d.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="pytorch-FTorch_files/libs/quarto-contrib/qrcodejs-v1.0.0/qrcode.js"></script>
<link href="pytorch-FTorch_files/libs/quarto-contrib/fontawesome6-6.7.2/all.min.css" rel="stylesheet">
<link href="pytorch-FTorch_files/libs/quarto-contrib/fontawesome6-6.7.2/latex-fontsize.css" rel="stylesheet"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.8.25">

  <meta name="dcterms.date" content="2025-10-23">
  <title> A Library To Couple PyTorch ML Models With Fortran Climate Models </title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="pytorch-FTorch_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="pytorch-FTorch_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    html { -webkit-text-size-adjust: 100%; }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #97947a;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #97947a;  padding-left: 4px; }
    div.sourceCode
      { color: #f8f8f2; background-color: #2b2b2b; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #f8f8f2; } /* Normal */
    code span.al { color: #dcc6e0; } /* Alert */
    code span.an { color: #d4d0ab; } /* Annotation */
    code span.at { color: #ffd700; } /* Attribute */
    code span.bn { color: #dcc6e0; } /* BaseN */
    code span.bu { color: #f5ab35; } /* BuiltIn */
    code span.cf { color: #ffa07a; } /* ControlFlow */
    code span.ch { color: #abe338; } /* Char */
    code span.cn { color: #ffa07a; } /* Constant */
    code span.co { color: #d4d0ab; } /* Comment */
    code span.cv { color: #d4d0ab; font-style: italic; } /* CommentVar */
    code span.do { color: #d4d0ab; font-style: italic; } /* Documentation */
    code span.dt { color: #dcc6e0; } /* DataType */
    code span.dv { color: #dcc6e0; } /* DecVal */
    code span.er { color: #dcc6e0; } /* Error */
    code span.ex { color: #ffd700; } /* Extension */
    code span.fl { color: #f5ab35; } /* Float */
    code span.fu { color: #ffd700; } /* Function */
    code span.im { } /* Import */
    code span.in { color: #d4d0ab; } /* Information */
    code span.kw { color: #ffa07a; } /* Keyword */
    code span.op { color: #00e0e0; } /* Operator */
    code span.ot { color: #ffa07a; } /* Other */
    code span.pp { color: #dcc6e0; } /* Preprocessor */
    code span.sc { color: #00e0e0; } /* SpecialChar */
    code span.ss { color: #abe338; } /* SpecialString */
    code span.st { color: #abe338; } /* String */
    code span.va { color: #f5ab35; } /* Variable */
    code span.vs { color: #abe338; } /* VerbatimString */
    code span.wa { color: #d4d0ab; font-style: italic; } /* Warning */
    /* CSS for citations */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
      margin-bottom: 0em;
    }
    .hanging-indent div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }  </style>
  <link rel="stylesheet" href="pytorch-FTorch_files/libs/revealjs/dist/theme/quarto-9c45e75a6e22bf5c36cf0b941fbced29.css">
  <link href="pytorch-FTorch_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="pytorch-FTorch_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="pytorch-FTorch_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="pytorch-FTorch_files/libs/revealjs/plugin/reveal-attribution/attribution.css" rel="stylesheet">
  <link href="pytorch-FTorch_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  <style>
  #title-slide .title {
    font-size: 1.25em;
    color: #fffff;
  }
  #title-slide .authors {
    font-size: 1.0em;
    color: #fffff;
  }
  #title-slide .title::before {
    content: "";
    display: inline-block;
    vertical-align: middle;
    width: 350px;
    height: 100px;
    background: url('./images/logos/FTorch.svg') no-repeat center/contain;
  }
  </style>
</head>
<body class="quarto-dark">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title"><br><br>A Library To Couple PyTorch ML Models With Fortran Climate Models<br><br></h1>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Matt Archer <a href="https://orcid.org/0009-0002-7043-6769" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a>
</div>
        <p class="quarto-title-affiliation">
            Senior Research Software Engineer <br> <code>ICCS</code> - <code>I</code>nstitute of <code>C</code>omputing for <code>C</code>limate <code>S</code>cience <br> University of Cambridge
          </p>
    </div>
</div>

  <p class="date">2025-10-23</p>
</section>
<section class="slide level2">

<!-- ## Precursors {.smaller .nostretch} -->
<!-- :::: {.columns} -->
<!-- ::: {.column width="45%"} -->
<!-- #### Slides and Materials -->
<!-- To access links or follow on your own device these slides can be found at:\ -->
<!-- [jackatkinson.net/slides](https://jackatkinson.net/slides) -->
<!-- ::: {style="text-align: center"} -->
<!--  -->
<!-- ::: -->
<!-- ::: -->
<!-- ::: {.column width="5%"} -->
<!-- ::: -->
<!-- ::: {.column width="50%"} -->
<!-- #### Licensing -->
<!-- Except where otherwise noted, these presentation materials are licensed under the Creative Commons -->
<!-- [Attribution-NonCommercial 4.0 International](https://creativecommons.org/licenses/by-nc/4.0/legalcode) ([CC BY-NC 4.0](https://creativecommons.org/licenses/by-nc/4.0/)) License. -->
<!-- ![]( https://mirrors.creativecommons.org/presskit/buttons/88x31/svg/by-nc.eu.svg ){width=40% fig-align="center"} -->
<!-- Vectors and icons by [SVG Repo](https://www.svgrepo.com) -->
<!-- under [CC0(1.0)](https://creativecommons.org/publicdomain/zero/1.0/deed.en) or -->
<!-- [FontAwesome](https://fontawesome.com/) under [SIL OFL 1.1](http://scripts.sil.org/OFL) -->
<!-- ::: -->
<!-- :::: -->
<!-- =============================================================================== -->
<!-- ## The ICCS

! ## The ICCS^[For more details see poster 14 *International RSE collaboration with the ICCS and the VESRI*] {.smaller}

The Institute of Computing for Climate Science

* Domain-specific RSE group based at the University of Cambridge
* Embedded support to several international climate science projects 

![]( ./images/iccs/ICCS_streams.png){fig-align="center"}

::: {.notes}
My background in this is ML and numerical modelling on HPC. 
::: -->
</section>
<section id="weather-and-climate-models" class="slide level2 smaller">
<h2>Weather and Climate Models</h2>
<p>Large, complex, many-part systems. <br></p>

<img data-src="./images/Climate_Models.svg" class="r-stretch"></section>
<section id="parameterisation" class="slide level2 smaller" data-auto-animate="true">
<h2 data-id="quarto-animate-title">Parameterisation</h2>
<p>Subgrid processes are largest source of uncertainty</p>
<p><img data-src="https://nps.edu/documents/10180/113643263/nps-tschneider-gclimatemodel-grid.jpg/de62c0fe-c76f-42e7-abdf-3143935b1fb3?t=1551741588000.png" class="absolute" style="height: 50%; width=20px; object-fit: cover; object-position: 0 0;top: 25%; left: 0%; "></p>
<p><img data-src="https://sisichenclouds.weebly.com/uploads/1/3/0/6/130656471/cloudprocess1_orig.png" class="absolute" style="background: #FFFFFF;top: 53%; left: 44%; height: 0.5%; "></p>
<div class="attribution">
<p>Microphysics by Sisi Chen Public Domain<br>
Staggered grid by NOAA under Public Domain<br>
Globe grid with box by Caltech under Fair use</p>
</div>
</section>
<section id="parameterisation-1" class="slide level2 smaller" data-auto-animate="true">
<h2 data-id="quarto-animate-title">Parameterisation</h2>
<p>Subgrid processes are largest source of uncertainty</p>
<p><img data-src="https://nps.edu/documents/10180/113643263/nps-tschneider-gclimatemodel-grid.jpg/de62c0fe-c76f-42e7-abdf-3143935b1fb3?t=1551741588000.png" class="absolute" style="height: 50%; width=20px; object-fit: cover; object-position: 0 0;top: 25%; left: 0%; "></p>
<p><img data-src="https://sisichenclouds.weebly.com/uploads/1/3/0/6/130656471/cloudprocess1_orig.png" class="absolute" style="background: #FFFFFF;top: 30%; right: 0%; height: 40%; "></p>
<div class="attribution">
<p>Microphysics by Sisi Chen Public Domain<br>
Staggered grid by NOAA under Public Domain<br>
Globe grid with box by Caltech under Fair use</p>
</div>
</section>
<section id="hybrid-modelling" class="slide level2 smaller">
<h2>Hybrid Modelling</h2>
<p><br></p>
<div style="width:95%;margin:auto;">
<p><img data-src="./images/Climate_Models.svg" id="climate"></p>
</div>
<p><img data-src="./images/neural_net_3b1b.jpeg" class="fragment absolute" style="border-radius:50%;left: 56%; bottom: 7%; width: 25%; height: 21%; "></p>
<div class="attribution">
<p>Neural Net by <a href="https://www.3blue1brown.com/topics/neural-networks">3Blue1Brown</a> under <a href="https://www.gov.uk/guidance/exceptions-to-copyright"><em>fair dealing</em></a>.</p>
</div>
</section>
<section id="end-to-end" class="slide level2 smaller">
<h2>End-to-End</h2>

<img data-src="./images/AURORA_Fig1.png" class="r-stretch"><div class="attribution">
<p>https://www.microsoft.com/en-us/research/project/aurora-forecasting/</p>
</div>
<!-- =============================================================================== -->
</section>
<section id="language-interoperation" class="slide level2 smaller">
<h2>Language interoperation</h2>
<p>Many large scientific models are written in Fortran (or C, or C++), but machine learning is (mostly) conducted in Python.</p>
<p><img data-src="https://upload.wikimedia.org/wikipedia/commons/5/55/Mathematical_Bridge_tangents.jpg" class="absolute" style="border-radius: 50%;top: 27%; left: 30%; width: 40%; "></p>
<p><img data-src="https://www.python.org/static/community_logos/python-logo-generic.svg" class="absolute" style="top: 40%; left: 0px; width: 30%; "></p>
<!-- ![]( https://raw.githubusercontent.com/pytorch/pytorch/main/docs/source/_static/img/pytorch-logo-dark.png ){style="background-image: radial-gradient(gray 0%, #03334E 100%);" .absolute top=55% left=5% width=20%} -->
<p><img data-src="https://raw.githubusercontent.com/pytorch/pytorch/main/docs/source/_static/img/pytorch-logo-dark.png" class="absolute" style="background-image: radial-gradient(gray 30%, #03334E 75%);top: 65%; left: 5%; width: 40%; "></p>
<!-- ![]( https://upload.wikimedia.org/wikipedia/commons/thumb/1/11/TensorFlowLogo.svg/696px-TensorFlowLogo.svg.png?20180105010857 ){.absolute top=65% left=7.5% width=15%} -->
<p><img data-src="https://raw.githubusercontent.com/fortran-lang/fortran-lang.org/bbdc33ec7bfc06fa6111093ae9712a7f7837b555/assets/img/fortran-logo.svg" class="absolute" style="top: 40%; right: 10%; width: 10%; "></p>
<p><img data-src="https://www.metoffice.gov.uk/binaries/content/gallery/metofficegovuk/images/about-us/website/mo_master_for_dark_backg_rbg.png" class="absolute" style="top: 55%; right: 0%; height: 10%; "></p>
<p><img data-src="https://climate.copernicus.eu/sites/default/files/custom-uploads/branding/ECMWF_Master_Logo_RGB_nostrap.png" class="absolute" style="top: 64.5%; left: 70%; height: 5%; "></p>
<p><img data-src="./images/logos/ICON.png" class="absolute" style="border-radius: 5%;bottom: 14.5%; right: 0px; width: 10%; "></p>
<p><img data-src="./images/logos/DWD.jpg" class="absolute" style="border-radius: 20%;bottom: 19.5%; right: 2%; width: 6%; "></p>
<p><img data-src="https://www2.mmm.ucar.edu/wrf/users/images/wrf_logo.jpg" class="absolute" style="bottom: 14.5%; right: 12.75%; width: 7%; "></p>
<p><img data-src="https://avatars.githubusercontent.com/u/33552285?s=200&amp;v=4.png" class="absolute" style="left: 70%; bottom: 14.5%; width: 7%; "></p>
<!--
::: {.fragment .fade-in-then-out}
![]( ./images/Fortran_TIOBE.jpg ){.absolute top=25% width=100%}
:::
-->
<div class="attribution">
<p><a href="https://en.wikipedia.org/wiki/Mathematical_Bridge">Mathematical Bridge</a> by <a href="https://commons.wikimedia.org/wiki/User:Cmglee">cmglee</a> used under <a href="https://creativecommons.org/licenses/by-sa/3.0/deed.en">CC BY-SA 3.0</a><br>
PyTorch, the PyTorch logo and any related marks are <a href="https://www.linuxfoundation.org/legal/trademark-usage">trademarks of The Linux Foundation</a>.”<br>
<!-- TensorFlow, the TensorFlow logo and any related marks are trademarks of Google Inc. --></p>
</div>
<aside class="notes">
<p>Emulation and data-driven is a focus of several of our projects. CALIPSO, M2LInES, DataWave, etc.<br>
Models typically in Fortran<br>
ML typically in Python</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<!-- ::: aside
Circa. 2022. More solutions emerging as the field grows e.g. TorchFort, Neural-Fortran, FIATS etc.
<!-- ::: -->
<!-- =============================================================================== -->
</section>
<section id="ftorch" class="slide level2 smaller">
<h2>FTorch</h2>
<ul>
<li><em>PyTorch</em> has a C++ backend and provides an API.<br>
</li>
<li>Binding Fortran to C is straightforward<sup>1</sup> from 2003 using <code>iso_c_binding</code>.</li>
</ul>
<p>We will:</p>
<ul>
<li>Provide a Fortran API
<ul>
<li>wrapping the <code>libtorch</code> C++ API</li>
<li>abstracting complex details from users</li>
</ul></li>
<li>Save the PyTorch models in a portable <a href="https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html">Torchscript</a> format
<ul>
<li>to be run by <code>libtorch</code> C++</li>
</ul></li>
</ul>
<aside class="notes">
<p>TorchScript is a statically typed subset of Python</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<!-- ## Efficiency {auto-animate=true, .smaller}

We consider 2 types:

:::: {.columns}
::: {.column width="50%"}
Computational

  ![]( https://www.svgrepo.com/show/521584/cpu.svg ){style="filter: invert(100%)" width=15%}
  ![]( https://www.svgrepo.com/show/42898/ram-memory.svg ){style="filter: invert(100%)" width=15%}
  ![]( https://www.svgrepo.com/show/325133/electronics-transister.svg ){style="filter: invert(100%)" width=15%}
  ![]( https://www.svgrepo.com/show/479706/stopwatch.svg ){style="filter: invert(100%)" width=15%}
:::
::: {.column}
Developer

  ![]( https://www.svgrepo.com/show/308093/software-developer-work-on-computer-programmer-coder.svg ){style="filter: invert(100%)" width=15%}
  ![]( https://www.svgrepo.com/show/67720/brain-speech-bubble.svg ){style="filter: invert(100%)" width=15%}
  ![]( https://www.svgrepo.com/show/490654/coffee-maker.svg ){style="filter: invert(100%)" width=15%}
  ![]( https://www.svgrepo.com/show/479706/stopwatch.svg ){style="filter: invert(100%)" width=15%}
:::

::: {.column}
::: {.fragment}
An ideal solution should:

* not generate excess additional work,
  * not require advanced computing skills,
  * have a minimal learning curve,
* not add excess dependencies,
* be easy to maintain, and
* maximise performance.
:::
:::

::::

In research both have an effect on 'time-to-science'.\
Especially when extensive research software support is unavailable.

::: {.notes}
1. No re-writing net after you have already done and trained
2. For scientists doing science, not compsci
3. Run on HPC environments so minimal additional 
4. Easily keep up to date
5. Simple to learn and deploy
6. Needs to be as efficient as possible
::: -->
<aside><ol class="aside-footnotes"><li id="fn1"><p>A dangerous word, rather, ‘well supported’?</p></li></ol></aside></section>
<section id="approach" class="slide level2 smaller">
<h2>Approach</h2>
<p><img data-src="https://raw.githubusercontent.com/fortran-lang/fortran-lang.org/bbdc33ec7bfc06fa6111093ae9712a7f7837b555/assets/img/fortran-logo.svg" class="absolute" style="top: 10%; right: 12.5%; width: 15%; "></p>
<p><img data-src="https://www.freepngimg.com/thumb/youtube/77810-arrows-marketing-youtube-arrow-red-free-transparent-image-hq.png" class="absolute" style="top: 20%; right: 30%; width: 35%; height: 20%; "></p>
<p><img data-src="https://s3.dualstack.us-east-2.amazonaws.com/pythondotorg-assets/media/community/logos/python-logo-only.png" class="absolute" style="top: 40%; left: 30%; height: 20%; "></p>
<p><img data-src="https://www.freepngimg.com/thumb/youtube/77810-arrows-marketing-youtube-arrow-red-free-transparent-image-hq.png" class="absolute" style="transform: rotate(270deg);top: 70%; left: 30%; width: 18%; height: 10%; "></p>
<p><img data-src="https://www.pngall.com/wp-content/uploads/5/Open-Box-PNG-Clipart.png" class="absolute" style="top: 18%; left: 0%; height: 22%; "></p>
<p><img data-src="https://www.freepngimg.com/thumb/youtube/77810-arrows-marketing-youtube-arrow-red-free-transparent-image-hq.png" class="absolute" style="transform: rotate(270deg);top: 33%; left: 14%; width: 10%; height: 25%; "></p>
<div class="absolute" style="text-align: center; color: black;top: 27%; left: 6.5%; ">
<p>Python<br>
env</p>
</div>
<div class="absolute" style="text-align: center;top: 44%; left: 44%; ">
<p>Python<br>
runtime</p>
</div>
<p><img data-src="https://raw.githubusercontent.com/pytorch/pytorch/main/docs/source/_static/img/pytorch-logo-dark.png" class="absolute" style="background-image: radial-gradient(gray 0%, #03334E 75%);bottom: 12.5%; right: 5%; height: 15%; "></p>
<!-- ![](https://upload.wikimedia.org/wikipedia/commons/thumb/1/11/TensorFlowLogo.svg/696px-TensorFlowLogo.svg.png?20180105010857){.absolute bottom=10% left=82% height=15%} -->
<div class="fragment fade-in-then-semi-out">
<p><img data-src="https://imgs.xkcd.com/comics/python_environment_2x.png" class="absolute" style="left: 0%; bottom: 13%; height: 70%; "></p>
</div>
<div class="attribution">
<p><a href="https://xkcd.com/1987/">xkcd #1987</a> by Randall Munroe, used under <a href="https://creativecommons.org/licenses/by-nc/2.5/">CC BY-NC 2.5</a></p>
</div>
<div class="fragment fade-in">
<p><img data-src="https://www.freepngimg.com/thumb/youtube/77810-arrows-marketing-youtube-arrow-red-free-transparent-image-hq.png" class="absolute" style="transform: scaleY(-1) rotate(130deg); filter:hue-rotate(150deg);top: 37%; left: 78%; width: 35%; height: 20%; "></p>
</div>
<!-- 
## Highlights - Developer {.smaller auto-animate=true}

:::: {.columns}
::: {.column width="65%" style="line-height: 1.8; margin-right: 2em;"}

- Easy to clone and install
  - CMake, supported on linux/unix and Windows&#8482;

- Easy to link
  - Build using CMake,
  - or link via Make like NetCDF (instructions included)\
    ```
    FCFLAGS += -I<path/to/install>/include/ftorch
    LDFLAGS += -L<path/to/install>/lib64 -lftorch
    ```

:::
::: {.column width="35%"}
Find it on :



[/Cambridge-ICCS/FTorch](https://github.com/Cambridge-ICCS/FTorch)
:::
:::: -->
</section>
<section id="highlights---developer" class="slide level2 smaller">
<h2>Highlights - Developer</h2>
<div class="columns">
<div class="column" style="line-height: 1.8; margin-right: 2em;">
<div class="fragment">
<ul>
<li><p>Easy to build and link using CMake,</p>
<ul>
<li>or link via Make like NetCDF</li>
</ul></li>
<li><p>User tools</p>
<ul>
<li><a href="https://github.com/Cambridge-ICCS/FTorch/tree/main/utils"><code>pt2ts.py</code></a> aids users in saving PyTorch models to Torchscript</li>
</ul></li>
<li><p>Examples suite</p>
<ul>
<li>Take users through full process from trained net to Fortran inference</li>
</ul></li>
<li><p>Full API documentation online at<br>
<a href="https://cambridge-iccs.github.io/FTorch/">cambridge-iccs.github.io/FTorch</a></p></li>
<li><p>FOSS, licensed under MIT</p>
<ul>
<li>Contributions via GitHub welcome</li>
</ul></li>
</ul>
</div>
</div><div class="column" style="width:35%;">
<p>Find it on <i class="fa-brands fa-github" aria-label="github"></i>:</p>
<div id="id=" "="" class="qrcode"></div>
<script type="text/javascript">
(function() {
  var script = document.currentScript;
  var qrcode = script.previousElementSibling;
  qrcode.qrcode = new QRCode(qrcode, {"colorDark":"#000000","colorLight":"#ffffff","height":"200","text":"https://github.com/Cambridge-ICCS/FTorch","width":"200"});
  script.remove();
})();
</script>
    
<p><a href="https://github.com/Cambridge-ICCS/FTorch"><i class="fa-brands fa-github" aria-label="github"></i>/Cambridge-ICCS/FTorch</a></p>
</div></div>
</section>
<section id="highlights---computation" class="slide level2 smaller" data-auto-animate="true">
<h2 data-id="quarto-animate-title">Highlights - Computation</h2>
<div class="columns">
<div class="column" style="line-height: 1.8; margin-right: 2em;">
<div class="fragment">
<ul>
<li>Use framework’s implementations directly
<ul>
<li>feature and future support, and reproducible</li>
</ul></li>
<li>Make use of the Torch backends for GPU offload
<ul>
<li><code>CUDA</code>, <code>HIP</code>, <code>MPS</code>, and <code>XPU</code> enabled</li>
</ul></li>
</ul>
</div>
</div><div class="column" style="width:35%;">
<p>Find it on <i class="fa-brands fa-github" aria-label="github"></i>:</p>
<div id="id=" "="" class="qrcode"></div>
<script type="text/javascript">
(function() {
  var script = document.currentScript;
  var qrcode = script.previousElementSibling;
  qrcode.qrcode = new QRCode(qrcode, {"colorDark":"#000000","colorLight":"#ffffff","height":"200","text":"https://github.com/Cambridge-ICCS/FTorch","width":"200"});
  script.remove();
})();
</script>
    
<p><a href="https://github.com/Cambridge-ICCS/FTorch"><i class="fa-brands fa-github" aria-label="github"></i>/Cambridge-ICCS/FTorch</a></p>
</div></div>
</section>
<section id="highlights---computation-1" class="slide level2 smaller" data-auto-animate="true">
<h2 data-id="quarto-animate-title">Highlights - Computation</h2>
<div class="columns">
<div class="column" style="width:65%;">
<ul>
<li>Indexing issues and associated reshape<sup>1</sup> avoided with Torch strided accessor.</li>
<li>No-copy access in memory (on CPU).</li>
</ul>
<p><img data-src="./images/f_pt_shared_memory.svg"></p>
</div><div class="column" style="width:35%;">
<p>Find it on <i class="fa-brands fa-github" aria-label="github"></i>:</p>
<div id="id=" "="" class="qrcode"></div>
<script type="text/javascript">
(function() {
  var script = document.currentScript;
  var qrcode = script.previousElementSibling;
  qrcode.qrcode = new QRCode(qrcode, {"colorDark":"#000000","colorLight":"#ffffff","height":"200","text":"https://github.com/Cambridge-ICCS/FTorch","width":"200"});
  script.remove();
})();
</script>
    
<p><a href="https://github.com/Cambridge-ICCS/FTorch"><i class="fa-brands fa-github" aria-label="github"></i>/Cambridge-ICCS/FTorch</a></p>
</div></div>
<aside><ol class="aside-footnotes"><li id="fn2"><p>Or, the great row-major, column-major headache.</p></li></ol></aside></section>
<section id="saving-model-from-python" class="slide level2 smaller">
<h2>Saving model from Python</h2>
<!-- ```{.python .code-overflow-wrap code-line-numbers="|4-6|11,12-13|11,14-15|16-17"} -->
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1"><pre class="sourceCode numberSource python code-overflow-wrap number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href=""></a><span class="im">import</span> torch</span>
<span id="cb1-2"><a href=""></a><span class="im">import</span> torchvision</span>
<span id="cb1-3"><a href=""></a></span>
<span id="cb1-4"><a href=""></a><span class="co"># Load pre-trained model and put in eval mode</span></span>
<span id="cb1-5"><a href=""></a>model <span class="op">=</span> torchvision.models.resnet18(weights<span class="op">=</span><span class="st">"IMAGENET1K_V1"</span>)</span>
<span id="cb1-6"><a href=""></a>model.<span class="bu">eval</span>()</span>
<span id="cb1-7"><a href=""></a></span>
<span id="cb1-8"><a href=""></a><span class="co"># Create dummmy input</span></span>
<span id="cb1-9"><a href=""></a>dummy_input <span class="op">=</span> torch.ones(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">224</span>, <span class="dv">224</span>)</span>
<span id="cb1-10"><a href=""></a></span>
<span id="cb1-11"><a href=""></a><span class="co"># Save to TorchScript</span></span>
<span id="cb1-12"><a href=""></a><span class="cf">if</span> trace:</span>
<span id="cb1-13"><a href=""></a>    ts_model <span class="op">=</span> torch.jit.trace(model, dummy_input)</span>
<span id="cb1-14"><a href=""></a><span class="cf">elif</span> script:</span>
<span id="cb1-15"><a href=""></a>    ts_model <span class="op">=</span> torch.jit.script(model)</span>
<span id="cb1-16"><a href=""></a>frozen_model <span class="op">=</span> torch.jit.freeze(ts_model)</span>
<span id="cb1-17"><a href=""></a>frozen_model.save(<span class="st">"/path/to/saved_model.pt"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><img data-src="https://s3.dualstack.us-east-2.amazonaws.com/pythondotorg-assets/media/community/logos/python-logo-only.png" class="absolute" style="top: 15%; right: 3%; height: 6%; "></p>
<p>TorchScript</p>
<ul>
<li>Statically typed subset of Python</li>
<li>Read by the Torch C++ interface (or any Torch API)</li>
<li>Produces intermediate representation/graph of NN, including weights and biases</li>
<li><code>trace</code> for simple models, <code>script</code> more generally</li>
<li>Soon to be deprecated - ExecuTorch?</li>
</ul>
</section>
<section id="fortran" class="slide level2">
<h2>Fortran</h2>
<div style="font-size: 0.7em">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb2" data-code-line-numbers="|1|7,11-15|8,17|18|22-25"><pre class="sourceCode numberSource fortranfree number-lines code-with-copy"><code class="sourceCode fortranfree"><span id="cb2-1"><a href=""></a> <span class="kw">use</span> ftorch</span>
<span id="cb2-2"><a href=""></a> </span>
<span id="cb2-3"><a href=""></a> <span class="kw">implicit</span> <span class="kw">none</span></span>
<span id="cb2-4"><a href=""></a> </span>
<span id="cb2-5"><a href=""></a> <span class="dt">real</span>, <span class="dt">dimension(5)</span>, <span class="dt">target</span> <span class="dt">::</span> in_data, out_data  <span class="co">! Fortran data structures</span></span>
<span id="cb2-6"><a href=""></a> </span>
<span id="cb2-7"><a href=""></a> <span class="dt">type(torch_tensor)</span>, <span class="dt">dimension(1)</span> <span class="dt">::</span> input_tensors, output_tensors  <span class="co">! Set up Torch data structures</span></span>
<span id="cb2-8"><a href=""></a> <span class="dt">type(torch_model)</span> <span class="dt">::</span> torch_net</span>
<span id="cb2-9"><a href=""></a> <span class="dt">integer</span>, <span class="dt">dimension(1)</span> <span class="dt">::</span> tensor_layout <span class="kw">=</span> <span class="kw">[</span><span class="dv">1</span><span class="kw">]</span></span>
<span id="cb2-10"><a href=""></a> </span>
<span id="cb2-11"><a href=""></a> in_data <span class="kw">=</span> ...  <span class="co">! Prepare data in Fortran</span></span>
<span id="cb2-12"><a href=""></a> </span>
<span id="cb2-13"><a href=""></a> <span class="co">! Create Torch input/output tensors from the Fortran arrays</span></span>
<span id="cb2-14"><a href=""></a> <span class="kw">call</span> torch_tensor_from_array(input_tensors(<span class="dv">1</span>), in_data, torch_kCPU)</span>
<span id="cb2-15"><a href=""></a> <span class="kw">call</span> torch_tensor_from_array(output_tensors(<span class="dv">1</span>), out_data, torch_kCPU)</span>
<span id="cb2-16"><a href=""></a> </span>
<span id="cb2-17"><a href=""></a> <span class="kw">call</span> torch_model_load(torch_net, <span class="st">'path/to/saved/model.pt'</span>, torch_kCPU)  <span class="co">! Load ML model</span></span>
<span id="cb2-18"><a href=""></a> <span class="kw">call</span> torch_model_forward(torch_net, input_tensors, output_tensors)      <span class="co">! Infer</span></span>
<span id="cb2-19"><a href=""></a> </span>
<span id="cb2-20"><a href=""></a> <span class="kw">call</span> further_code(out_data)  <span class="co">! Use output data in Fortran immediately</span></span>
<span id="cb2-21"><a href=""></a> </span>
<span id="cb2-22"><a href=""></a> <span class="co">! Cleanup</span></span>
<span id="cb2-23"><a href=""></a> <span class="kw">call</span> torch_delete(model)</span>
<span id="cb2-24"><a href=""></a> <span class="kw">call</span> torch_delete(in_tensors)</span>
<span id="cb2-25"><a href=""></a> <span class="kw">call</span> torch_delete(out_tensor)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p><img data-src="https://raw.githubusercontent.com/fortran-lang/fortran-lang.org/bbdc33ec7bfc06fa6111093ae9712a7f7837b555/assets/img/fortran-logo.svg" class="absolute" style="top: 16%; right: 3%; height: 5%; "></p>
<!-- ## GPU Acceleration {.smaller}

Cast Tensors to GPU in Fortran:

```{.fortranfree .code-overflow-wrap .code-overflow-wrap code-line-numbers="|5|6|"}
! Load in from Torchscript
call torch_model_load(torch_net, 'path/to/saved/model.pt', torch_kCUDA, device_index=0)

! Cast Fortran data to Tensors
call torch_tensor_from_array(in_tensor(1), in_data, torch_kCUDA, device_index=0)
call torch_tensor_from_array(out_tensor(1), out_data, torch_kCPU)
```

![]( https://raw.githubusercontent.com/fortran-lang/fortran-lang.org/bbdc33ec7bfc06fa6111093ae9712a7f7837b555/assets/img/fortran-logo.svg ){.absolute top=21% right=3% height=5%}

\
\

FTorch supports NVIDIA `CUDA`, ARM `HIP`, Intel `XPU`, and AppleSilicon `MPS` hardwares.

Use of multiple devices supported.

\

Effective HPC simulation requires `MPI_Gather()` for efficient data transfer.


::: {.notes}
Through developing a nice library it behaves as you would expect it to!  
Familiar to pytorch users.  
Pointer slinging is largely hidden from users.  
Data transposition is taken care of by us (but options available for users to handle).
::: -->
<!-- 
## Publication & tutorials {.smaller}


FTorch is published in JOSS!

Please cite if you use FTorch.

\

:::: {.columns}
::: {.column width="35%"}
![]( ./images/logos/JOSS_logo.jpg){width=90%}
:::

::: {.column width="65%"}
@Atkinson2025

FTorch: a library for coupling PyTorch models to Fortran.\
_Journal of Open Source Software_, 10(107), 7602,\
[doi.org/10.21105/joss.07602](https://doi.org/10.21105/joss.07602)
:::
::::

\

In addition to the comprehensive examples in the FTorch repository we
provide an online workshop at [/Cambridge-ICCS/FTorch-workshop](https://github.com/Cambridge-ICCS/FTorch-workshop) -->
<!-- {{< include _case_studies.qmd >}} -->
<!-- =============================================================================== -->
</section>
<section id="online-training-and-autograd" class="slide level2 smaller">
<h2>Online training and autograd</h2>
<p>Work led by <a href="https://joewallwork.com/">Joe Wallwork</a></p>
<p>To date FTorch has focussed on enabling researchers to run models developed and trained offline within Fortran codes.</p>
<p>However, it is clear <span class="citation" data-cites="mansfield2024uncertainty">(<a href="#/references" role="doc-biblioref" onclick="">Mansfield and Sheshadri 2024</a>)</span> that more attention to online performance, and options with differentiable/hybrid models <span class="citation" data-cites="kochkov2024neural">(e.g. <a href="#/references" role="doc-biblioref" onclick="">Kochkov et al. 2024</a>)</span> is becoming important.</p>
<h4 id="pros">Pros:</h4>
<ul>
<li>Avoids saving large volumes of training data.</li>
<li>Avoids need to convert between Python and Fortran data formats.</li>
<li>Possibility to expand loss function scope to include downstream model code.</li>
</ul>
<h4 id="cons">Cons:</h4>
<ul>
<li>Difficult to implement in most frameworks.</li>
</ul>
</section>
<section id="expanded-loss-function" class="slide level2 smaller">
<h2>Expanded Loss function</h2>
<p>Suppose we want to use a loss function involving downstream model code, e.g.,</p>
<p><span class="math display">\[J(\theta)=\int_\Omega(u-u_{ML}(\theta))^2\;\mathrm{d}x,\]</span></p>
<p>where <span class="math inline">\(u\)</span> is the solution from the physical model and <span class="math inline">\(u_{ML}(\theta)\)</span> is the solution from a hybrid model with some ML parameters <span class="math inline">\(\theta\)</span>.</p>
<p>Computing <span class="math inline">\(\mathrm{d}J/\mathrm{d}\theta\)</span> requires differentiating Fortran code as well as ML code.</p>
</section>
<section id="implementing-ad-in-ftorch" class="slide level2 smaller">
<h2>Implementing AD in FTorch</h2>
<ul>
<li>Expose <code>autograd</code> functionality from Torch.
<ul>
<li>e.g., <code>requires_grad</code> argument and <code>backward</code> methods.</li>
</ul></li>
<li>Overload mathematical operators (<code>=</code>,<code>+</code>,<code>-</code>,<code>*</code>,<code>/</code>,<code>**</code>).</li>
</ul>
<!-- ## Using AD - FTorch {.smaller}

```fortranfree {code-line-numbers="|6-8|14-16|19|22-23"}
use ftorch

type(torch_tensor) :: a, b, Q, multiplier, divisor, dQda, dQdb
real, dimension(2), target :: Q_arr, dQda_arr, dQdb_arr

! Construct input tensors with requires_grad=.true.
call torch_tensor_from_array(a, [2.0, 3.0], torch_kCPU, requires_grad=.true.)
call torch_tensor_from_array(b, [6.0, 4.0], torch_kCPU, requires_grad=.true.)

! Workaround for scalar multiplication and division using 0D tensors
call torch_tensor_from_array(multiplier, [3.0], torch_kCPU)
call torch_tensor_from_array(divisor, [3.0], torch_kCPU)

! Compute some mathematical expression
call torch_tensor_from_array(Q, Q_arr, torch_kCPU)
Q = multiplier * (a**3 - b * b / divisor)

! Reverse mode
call torch_tensor_backward(Q)
call torch_tensor_from_array(dQda, dQda_arr, torch_kCPU)
call torch_tensor_from_array(dQdb, dQdb_arr, torch_kCPU)
call torch_tensor_get_gradient(a, dQda)
call torch_tensor_get_gradient(b, dQdb)
print *, dQda_arr
print *, dQdb_arr
``` -->
<ul>
<li>Optimizers
<ul>
<li>Expose <code>torch::optim::SGD</code>, <code>torch::optim::AdamW</code> etc., as well as <code>zero_grad</code> and <code>step</code> methods.</li>
<li>This already enables some cool AD applications in FTorch.</li>
</ul></li>
<li>Loss functions
<ul>
<li>We haven’t exposed any built-in loss functions yet.</li>
<li>Implemented <code>torch_tensor_sum</code> and <code>torch_tensor_mean</code>, though.</li>
</ul></li>
</ul>
<!-- 
## Putting it together - running an optimiser in FTorch {.smaller}

$$\begin{bmatrix}f_1\\f_2\\f_3\\f_4\end{bmatrix}=\mathbf{f}(\mathbf{x};\mathbf{a})=\mathbf{a}\bullet\mathbf{x}\equiv\begin{bmatrix}a_1x_1\\a_2x_2\\a_3x_3\\a_4x_4\end{bmatrix}$$
Starting from $\mathbf{a}=\mathbf{x}:=\begin{bmatrix}1,1,1,1\end{bmatrix}^T$, optimise the $\mathbf{a}$ vector such that $\mathbf{f}(\mathbf{x};\mathbf{a})=\mathbf{b}:=\begin{bmatrix}1,2,3,4\end{bmatrix}^T$.

Loss function: $\ell(\mathbf{a})=\overline{(\mathbf{f}(\mathbf{x};\mathbf{a})-\mathbf{b})^2}$.


## Putting it together - running an optimiser in FTorch {.smaller}

![](https://hackmd.io/_uploads/rybqzh961g.png)

In both cases we achieve $\mathbf{f}(\mathbf{x};\mathbf{a})=\begin{bmatrix}1,2,3,4\end{bmatrix}^T$.


## Case study - UKCA {.smaller}

* Implicit timestepping, quasi-Newton, full LU decomposition.
* For each time subinterval to be integrated:
  * Start with $\Delta t=3600$.
  * Try to integrate with the current timestep size.
  * If *any grid-box* fails, half the step and try again.
* A nice 'safe' application of machine learning in modelling -->
<!-- =============================================================================== -->
</section>
<section id="ftorch-summary" class="slide level2 smaller">
<h2>FTorch: Summary</h2>
<ul>
<li>Use of ML within traditional numerical models
<ul>
<li>A growing area that presents challenges</li>
</ul></li>
<li>Language interoperation
<ul>
<li>FTorch provides a solution for scientists implementing torch models in Fortran</li>
<li>Designed for <strong>computational</strong> <em>and</em> <strong>developer</strong> efficiency</li>
<li>Has helped deliver science in climate research and beyond<br>
see <span class="citation" data-cites="heuer2023interpretable">Heuer et al. (<a href="#/references" role="doc-biblioref" onclick="">2023</a>)</span>, <span class="citation" data-cites="mansfield2024uncertainty">Mansfield and Sheshadri (<a href="#/references" role="doc-biblioref" onclick="">2024</a>)</span> and more. <!-- - Built into CESM to allow the userbase access --></li>
</ul></li>
<li>Exploring options for online training and AD
<ul>
<li>Torch <code>autograd</code> and <code>optimizer</code> exposed using <code>iso_c_binding</code>.</li>
<li>Work in progress on setting up online ML training.</li>
</ul></li>
<li>Moving away from TorchScript…</li>
</ul>
<!-- =============================================================================== -->
</section>
<section id="thanks-for-listening" class="slide level2 smaller">
<h2>Thanks for Listening</h2>
<div class="columns">
<div class="column" style="width:20%; font-size: 85%;">
<p>Get in touch:</p>
</div><div class="column" style="width: 40%; font-size: 85%;">
<p><i class="fa-solid fa-pencil" aria-label="pencil"></i> &nbsp;Matt Archer</p>
<!--  \ [jackatkinson.net](https://jackatkinson.net) -->
<p><i class="fa-solid fa-envelope" aria-label="envelope"></i> &nbsp;<a href="mailto:jwa34@cam.ac.uk">ma595[AT]cam.ac.uk</a></p>
<p><i class="fa-brands fa-github" aria-label="github"></i> &nbsp;<a href="https://github.com/ma595">ma595</a></p>
<!--  \ [\@jatkinson1000\@hachyderm.io](https://hachyderm.io/@jatkinson1000) -->
</div><div class="column" style="width: 40%; font-size: 85%;">
<p><i class="fa-solid fa-pencil" aria-label="pencil"></i> &nbsp;Jack Atkinson</p>
<p><i class="fa-solid fa-globe" aria-label="globe"></i> &nbsp;<a href="https://jackatkinson.net">jackatkinson.net</a></p>
<p><i class="fa-solid fa-envelope" aria-label="envelope"></i> &nbsp;<a href="mailto:jwa34@cam.ac.uk">jwa34[AT]cam.ac.uk</a></p>
<p><i class="fa-brands fa-github" aria-label="github"></i> &nbsp;<a href="https://github.com/jatkinson1000">jatkinson1000</a></p>
<p><i class="fa-brands fa-mastodon" aria-label="mastodon"></i> &nbsp;<a href="https://hachyderm.io/@jatkinson1000">@jatkinson1000@hachyderm.io</a></p>
</div><!-- ::: {.column style="width: 40%; font-size: 85%;"}
 \ Joe Wallwork

 \ [joewallwork.com](https://joewallwork.com)

 \ [jw2423[AT]cam.ac.uk](mailto:jw2423@cam.ac.uk)

 \ [jwallwork23](https://github.com/jwallwork23)
::: -->
</div>
<p><br>
</p>
<div class="columns">
<div class="column" style="width:70%;">
<p>Thanks to <code>Jack Atkinson</code>, <code>Joe Wallwork</code>, Tom Meltzer,<br>
Elliott Kasoar, Niccolò Zanotti and the rest of the FTorch team.</p>
<p>The ICCS received support from <img data-src="./images/logos/schmidt_science.png" style="margin: 0; vertical-align: -2%;height:2.4em"></p>
<p>FTorch has been supported by <img data-src="./images/logos/c2d3_logo.png" style="margin: 0; vertical-align: -2%;height:1.4em"></p>
</div><div class="column" style="width:30%; font-size: 85%;">
<p><a href="https://github.com/Cambridge-ICCS/FTorch"><i class="fa-brands fa-github" aria-label="github"></i>/Cambridge-ICCS/FTorch</a></p>
<div id="" class="qrcode"></div>
<script type="text/javascript">
(function() {
  var script = document.currentScript;
  var qrcode = script.previousElementSibling;
  qrcode.qrcode = new QRCode(qrcode, {"colorDark":"#000000","colorLight":"#ffffff","height":"150","text":"https://github.com/Cambridge-ICCS/FTorch","width":"150"});
  script.remove();
})();
</script>
    
</div></div>
<p><img data-src="./images/logos/FTorch.svg" class="absolute" style="width: 12%;bottom: 28%; right: 2%; "></p>
<p><img data-src="https://iccs.cam.ac.uk/files/logo2_2.png" class="absolute" style="width: 12%;bottom: 19%; right: 2%; "></p>
</section>
<section id="references" class="slide level2 smaller scrollable">
<h2>References</h2>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-heuer2023interpretable" class="csl-entry" role="listitem">
Heuer, Helge, Mierk Schwabe, Pierre Gentine, Marco A Giorgetta, and Veronika Eyring. 2023. <span>“Interpretable Multiscale Machine Learning-Based Parameterizations of Convection for ICON.”</span> <em>arXiv Preprint arXiv:2311.03251</em>.
</div>
<div id="ref-kochkov2024neural" class="csl-entry" role="listitem">
Kochkov, Dmitrii, Janni Yuval, Ian Langmore, Peter Norgaard, Jamie Smith, Griffin Mooers, Milan Klöwer, et al. 2024. <span>“Neural General Circulation Models for Weather and Climate.”</span> <em>Nature</em> 632 (8027): 1060–66. <a href="https://doi.org/10.1038/s41586-024-07744-y">https://doi.org/10.1038/s41586-024-07744-y</a>.
</div>
<div id="ref-mansfield2024uncertainty" class="csl-entry" role="listitem">
Mansfield, Laura A, and Aditi Sheshadri. 2024. <span>“Uncertainty Quantification of a Machine Learning Subgrid-Scale Parameterization for Atmospheric Gravity Waves.”</span> <em>Authorea Preprints</em>.
</div>
</div>

</section>

    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<p><img src="https://iccs.cam.ac.uk/files/iccs_ucam_combined_reverse_colour.png" class="slide-logo"></p>
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="pytorch-FTorch_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="pytorch-FTorch_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="pytorch-FTorch_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="pytorch-FTorch_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="pytorch-FTorch_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="pytorch-FTorch_files/libs/revealjs/plugin/reveal-attribution/attribution.js"></script>
  <script src="pytorch-FTorch_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="pytorch-FTorch_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="pytorch-FTorch_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="pytorch-FTorch_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="pytorch-FTorch_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': true,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: false,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealAttribution, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
          const outerScaffold = trigger.parentElement.cloneNode(true);
          const codeEl = outerScaffold.querySelector('code');
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp('/' + window.location.host + '/');
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    

</body></html>